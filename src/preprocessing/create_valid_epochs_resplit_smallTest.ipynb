{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('./net2neuro')\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from simpleconv import SimpleConv\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/scratch/jd5697/cv_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(os.path.join(base_dir, 'image_embeddings_vit.npy'), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs(preproc_dir,all_epochs = []):\n",
    "    for p in range(1,n_participants+1):\n",
    "        epochs1 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo.fif', preload=False)\n",
    "        epochs2 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-1.fif', preload=False)\n",
    "        epochs3 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-2.fif', preload=False)\n",
    "        epochs = mne.concatenate_epochs([epochs1, epochs2, epochs3])\n",
    "        all_epochs.append(epochs)\n",
    "        del epochs1, epochs2, epochs3, epochs\n",
    "    return all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P1-epo-1.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:4: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P1-epo-1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs2 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-1.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P1-epo-2.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:5: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P1-epo-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs3 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-2.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Adding metadata with 18 columns\n",
      "27048 matching events found\n",
      "No baseline correction applied\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P2-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P2-epo-1.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:4: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P2-epo-1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs2 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-1.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P2-epo-2.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:5: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P2-epo-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs3 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-2.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Adding metadata with 18 columns\n",
      "27048 matching events found\n",
      "No baseline correction applied\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P3-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P3-epo-1.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:4: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P3-epo-1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs2 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-1.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P3-epo-2.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:5: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P3-epo-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs3 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-2.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Adding metadata with 18 columns\n",
      "27048 matching events found\n",
      "No baseline correction applied\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P4-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P4-epo-1.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:4: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P4-epo-1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs2 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-1.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P4-epo-2.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-54765026/ipykernel_3852051/1705987501.py:5: RuntimeWarning: This filename (/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new/preprocessed_P4-epo-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs3 = mne.read_epochs(f'{preproc_dir}/preprocessed_P{str(p)}-epo-2.fif', preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 18 columns\n",
      "9016 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Loading data for 9016 events and 181 original time points ...\n",
      "Adding metadata with 18 columns\n",
      "27048 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/scratch/jd5697/cv_project/THINGSmeg/ds004212/derivatives/preprocessed/new\"\n",
    "# all_epochs = mne.read_epochs(f'{base_path}/preprocessed_P1-epo.fif'\\\n",
    "#                              , preload = False)\n",
    "\n",
    "all_epochs = load_epochs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in all_epochs:\n",
    "    epoch.metadata['image_path'] = epoch.metadata.apply(\n",
    "        lambda row: row['image_path'][11:] if row['trial_type'] != 'test' else row['image_path'][16:], axis=1\n",
    "    )\n",
    "    # To make image path of test compatible \n",
    "    epoch.metadata['image_path'] = epoch.metadata.apply(\n",
    "        lambda row: f\"{'_'.join(row['image_path'].split('_')[:-1])}/{row['image_path']}\" if row['trial_type'] == 'test' else row['image_path'], axis=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #f\"{x.split('_')[0]}/{x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs[0].metadata['subject_index'] = 0\n",
    "all_epochs[1].metadata['subject_index'] = 1\n",
    "all_epochs[2].metadata['subject_index'] = 2\n",
    "all_epochs[3].metadata['subject_index'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs[1].info['dev_head_t'] =  all_epochs[0].info['dev_head_t']\n",
    "all_epochs[2].info['dev_head_t'] =  all_epochs[0].info['dev_head_t']\n",
    "all_epochs[3].info['dev_head_t'] =  all_epochs[0].info['dev_head_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "trial_type\n",
      "exp      22248\n",
      "catch     2400\n",
      "test      2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp      22248\n",
      "catch     2400\n",
      "test      2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp      22248\n",
      "test      2400\n",
      "catch     2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp      22248\n",
      "catch     2400\n",
      "test      2400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(all_epochs[0].metadata['trial_type'].unique()))\n",
    "\n",
    "# Get the number of values for each trial type in the metadata\n",
    "for i in range(n_participants):\n",
    "    print(all_epochs[i].metadata['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "trial_type\n",
      "exp     22248\n",
      "test     2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp     22248\n",
      "test     2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp     22248\n",
      "test     2400\n",
      "Name: count, dtype: int64\n",
      "trial_type\n",
      "exp     22248\n",
      "test     2400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop all the epochs where the trial type is catch\n",
    "for i in range(n_participants):\n",
    "    all_epochs[i] = all_epochs[i][all_epochs[i].metadata['trial_type'] != 'catch']\n",
    "    \n",
    "# Reset the metadata index\n",
    "for i in range(n_participants):\n",
    "    all_epochs[i].metadata = all_epochs[i].metadata.reset_index(drop=True)\n",
    "    \n",
    "# Get the number of values for each trial type in the metadata\n",
    "for i in range(n_participants):\n",
    "    print(all_epochs[i].metadata['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(epoch):\n",
    "    \n",
    "        \n",
    "    # Create separate epochs for training and testing\n",
    "    epoch_train = epoch[epoch.metadata['trial_type'] != 'test']\n",
    "    epoch_test = epoch[epoch.metadata['trial_type'] == 'test']\n",
    "    \n",
    "    # Reset the metadata index\n",
    "    epoch_train.metadata = epoch_train.metadata.reset_index(drop=True)\n",
    "    \n",
    "    # Add a column to metadata indicating if image_path is a duplicate\n",
    "    epoch_test.metadata['is_duplicate'] = epoch_test.metadata.duplicated(subset='image_path', keep='first')\n",
    "    epoch_test = epoch_test[epoch_test.metadata['is_duplicate'] == False]\n",
    "    \n",
    "    epoch_test.metadata = epoch_test.metadata.reset_index(drop=True)\n",
    "    \n",
    "    return epoch_train, epoch_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train = []\n",
    "epochs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 20 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 20 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 20 columns\n",
      "Replacing existing metadata with 19 columns\n",
      "Replacing existing metadata with 20 columns\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_participants):\n",
    "    epoch_train, epoch_test = partition_data(all_epochs[i])\n",
    "    epochs_train.append(epoch_train)\n",
    "    epochs_test.append(epoch_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22248\n",
      "22248\n",
      "22248\n",
      "22248\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for epoch in epochs_train:\n",
    "    print(len(epoch))\n",
    "    \n",
    "for epoch in epochs_test:\n",
    "    print(len(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del epochs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 20 columns\n",
      "800 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "#epochs_train = mne.concatenate_epochs(epochs_train)\n",
    "epochs_test = mne.concatenate_epochs(epochs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path\n",
      "candelabra/candelabra_14s.jpg                4\n",
      "baby/baby_17s.jpg                            4\n",
      "broccoli/broccoli_14s.jpg                    4\n",
      "seesaw/seesaw_13s.jpg                        4\n",
      "aircraft_carrier/aircraft_carrier_22s.jpg    4\n",
      "                                            ..\n",
      "limousine/limousine_15s.jpg                  4\n",
      "bell/bell_14n.jpg                            4\n",
      "floss/floss_13s.jpg                          4\n",
      "typewriter/typewriter_13s.jpg                4\n",
      "starfish/starfish_15n.jpg                    4\n",
      "Name: count, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(epochs_test.metadata['image_path'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = {}\n",
    "embeddings_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in epochs_train.metadata['image_path']:\n",
    "    embeddings_train[image_path] = embeddings[image_path]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in epochs_test.metadata['image_path']:\n",
    "    embeddings_test[image_path] = embeddings[image_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_train))\n",
    "print(len(embeddings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_epochs_small_train_resplit.pickle', 'wb') as f:\n",
    "    pickle.dump(epochs_train, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88992, 272, 181)\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "with open('valid_epochs_small_train_resplit.pickle', 'rb') as f:\n",
    "    epochs_train = pickle.load(f)\n",
    "\n",
    "print(epochs_train.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del epochs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_epochs_small_test_resplit.pickle', 'wb') as f:\n",
    "    pickle.dump(epochs_test, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 272, 181)\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "with open('valid_epochs_small_test_resplit.pickle', 'rb') as f:\n",
    "    epochs_test = pickle.load(f)\n",
    "\n",
    "print(epochs_test.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/dm5927/cv_project/net2neuro'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./image_embeddings_vit_small_train_resplit.npy', embeddings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(base_dir, 'image_embeddings_vit_test_small_resplit.npy'), embeddings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
