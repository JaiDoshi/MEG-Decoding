{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('./net2neuro')\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from simpleconv import SimpleConv\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/scratch/jd5697/cv_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24960\n",
      "9600\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "valid_epochs_all_train_fmri_subset = pickle.load(open(os.path.join(base_dir, 'valid_epochs_all_train_fmri_subset.pickle'), 'rb'))\n",
    "valid_epochs_all_test_fmri_subset = pickle.load(open(os.path.join(base_dir, 'valid_epochs_all_test_fmri_subset.pickle'), 'rb'))\n",
    "valid_epochs_all_test_small_fmri_subset = pickle.load(open(os.path.join(base_dir, 'valid_epochs_all_test_small_fmri_subset.pickle'), 'rb'))\n",
    "\n",
    "print(len(valid_epochs_all_train_fmri_subset))\n",
    "print(len(valid_epochs_all_test_fmri_subset))\n",
    "print(len(valid_epochs_all_test_small_fmri_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_into_epochs(valid_epochs, fmri_df):\n",
    "\n",
    "    valid_epochs.metadata =  valid_epochs.metadata.merge(fmri_df, left_on='image_path', right_on='stimulus', how='left')\n",
    "    valid_epochs.metadata.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = ['01', '02', '03']\n",
    "\n",
    "# Read files for each of the subjects and concat into one dataframe\n",
    "dfs = []\n",
    "for sub in subs:\n",
    "    df = pickle.load(open(os.path.join(base_dir, 'sub-{}_responses_fmri_svd.pkl'.format(sub)), 'rb'))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(name):\n",
    "    parts = name.split('/')\n",
    "    filename = parts[-1]\n",
    "    folder_name = '_'.join(filename.split('_')[:-1])\n",
    "    result = f\"{folder_name}/{filename}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dfs):\n",
    "    dfs[i]['stimulus'] = dfs[i]['stimulus'].apply(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Adding metadata with 28 columns\n",
      "74880 matching events found\n",
      "No baseline correction applied\n",
      "74880\n",
      "   trial_type_x  image_nr  category_nr  exemplar_nr  test_image_nr  \\\n",
      "2           exp      7522          627           10            NaN   \n",
      "8           exp      6802          567           10            NaN   \n",
      "9           exp     17050         1421           10            NaN   \n",
      "10          exp      5266          439           10            NaN   \n",
      "13          exp      8410          701           10            NaN   \n",
      "\n",
      "    things_category_nr  things_image_nr  things_exemplar_nr  \\\n",
      "2                627.0           9054.0                10.0   \n",
      "8                567.0           8217.0                10.0   \n",
      "9               1421.0          20164.0                10.0   \n",
      "10               439.0           6348.0                10.0   \n",
      "13               701.0          10046.0                10.0   \n",
      "\n",
      "                         image_path  onset  ...  subject_index  is_test  \\\n",
      "2             fondue/fondue_10s.jpg   6.00  ...              0    False   \n",
      "8     eyedropper/eyedropper_10s.jpg  14.85  ...              0    False   \n",
      "9             shield/shield_10s.jpg  16.45  ...              0    False   \n",
      "10  credit_card/credit_card_10s.jpg  17.90  ...              0    False   \n",
      "13          granite/granite_10s.jpg  22.35  ...              0    False   \n",
      "\n",
      "    trial_type_y  session  run  subject_id  trial_id  \\\n",
      "2          train        4    5           1      2833   \n",
      "8          train        4   10           1      3214   \n",
      "9          train        4    3           1      2678   \n",
      "10         train        4    4           1      2716   \n",
      "13         train        4    9           1      3153   \n",
      "\n",
      "                           stimulus      concept  \\\n",
      "2             fondue/fondue_10s.jpg       fondue   \n",
      "8     eyedropper/eyedropper_10s.jpg   eyedropper   \n",
      "9             shield/shield_10s.jpg       shield   \n",
      "10  credit_card/credit_card_10s.jpg  credit_card   \n",
      "13          granite/granite_10s.jpg      granite   \n",
      "\n",
      "                                                  svd  \n",
      "2   [1.4028856452302205, 5.024525737621864, -4.447...  \n",
      "8   [2.7511993303487645, 0.6430328756374994, 3.728...  \n",
      "9   [-5.255564434101364, 5.726373887209751, 0.3264...  \n",
      "10  [13.177805019991341, -0.8636546764807771, 0.92...  \n",
      "13  [-5.07266537516299, 6.782628319640241, -1.2560...  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "valid_epochs_train_list = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    valid_epochs = valid_epochs_all_train_fmri_subset.copy()\n",
    "    merge_into_epochs(valid_epochs, df)\n",
    "    valid_epochs_train_list.append(valid_epochs)\n",
    "\n",
    "valid_epochs_all_train_fmri_subset = mne.concatenate_epochs(valid_epochs_train_list)\n",
    "assert valid_epochs_all_train_fmri_subset.metadata['stimulus'].isna().sum() == 0\n",
    "print(len(valid_epochs_all_train_fmri_subset))\n",
    "print(valid_epochs_all_train_fmri_subset.metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Adding metadata with 28 columns\n",
      "28800 matching events found\n",
      "No baseline correction applied\n",
      "28800\n",
      "   trial_type_x  image_nr  category_nr  exemplar_nr  test_image_nr  \\\n",
      "3           exp      2950          246           10            NaN   \n",
      "28          exp     18994         1583           10            NaN   \n",
      "33          exp      3034          253           10            NaN   \n",
      "73          exp      1342          112           10            NaN   \n",
      "74          exp     12682         1057           10            NaN   \n",
      "\n",
      "    things_category_nr  things_image_nr  things_exemplar_nr  \\\n",
      "3                246.0           3648.0                10.0   \n",
      "28              1583.0          22357.0                10.0   \n",
      "33               253.0           3735.0                10.0   \n",
      "73               112.0           1704.0                10.0   \n",
      "74              1057.0          15050.0                10.0   \n",
      "\n",
      "                       image_path  onset  ...  subject_index  is_test  \\\n",
      "3             camel/camel_10s.jpg    7.5  ...              0     True   \n",
      "28          sundae/sundae_10s.jpg   44.6  ...              0     True   \n",
      "33  candelabra/candelabra_10s.jpg   51.6  ...              0     True   \n",
      "73                bee/bee_10s.jpg  113.3  ...              0     True   \n",
      "74              nest/nest_10s.jpg  114.8  ...              0     True   \n",
      "\n",
      "    trial_type_y  session  run  subject_id  trial_id  \\\n",
      "3          train        4    7           1      2960   \n",
      "28         train        4    9           1      3166   \n",
      "33         train        4    1           1      2487   \n",
      "73         train        4    2           1      2544   \n",
      "74         train        4    9           1      3182   \n",
      "\n",
      "                         stimulus     concept  \\\n",
      "3             camel/camel_10s.jpg       camel   \n",
      "28          sundae/sundae_10s.jpg      sundae   \n",
      "33  candelabra/candelabra_10s.jpg  candelabra   \n",
      "73                bee/bee_10s.jpg         bee   \n",
      "74              nest/nest_10s.jpg        nest   \n",
      "\n",
      "                                                  svd  \n",
      "3   [5.941845899560027, -1.6691985640757827, 11.14...  \n",
      "28  [-3.384337150683166, 4.684586009538524, -0.294...  \n",
      "33  [9.891943884865917, 4.508462919413001, -0.2467...  \n",
      "73  [7.530273358305646, 7.238017405480715, 2.86435...  \n",
      "74  [0.8407947980926245, 1.4963847537300388, -0.00...  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "valid_epochs_test_list = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    valid_epochs = valid_epochs_all_test_fmri_subset.copy()\n",
    "    merge_into_epochs(valid_epochs, df)\n",
    "    valid_epochs_test_list.append(valid_epochs)\n",
    "\n",
    "valid_epochs_all_test_fmri_subset = mne.concatenate_epochs(valid_epochs_test_list)\n",
    "assert valid_epochs_all_test_fmri_subset.metadata['stimulus'].isna().sum() == 0\n",
    "print(len(valid_epochs_all_test_fmri_subset))\n",
    "print(valid_epochs_all_test_fmri_subset.metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Replacing existing metadata with 28 columns\n",
      "Adding metadata with 28 columns\n",
      "1200 matching events found\n",
      "No baseline correction applied\n",
      "1200\n",
      "    trial_type_x  image_nr  category_nr  exemplar_nr  test_image_nr  \\\n",
      "14          test     22479          436           13           31.0   \n",
      "84          test     22540         1742           13           92.0   \n",
      "88          test     22534         1542           13           86.0   \n",
      "90          test     22545         1786           13           97.0   \n",
      "116         test     22482          514           13           34.0   \n",
      "\n",
      "     things_category_nr  things_image_nr  things_exemplar_nr  \\\n",
      "14                436.0           6312.0                15.0   \n",
      "84               1742.0          24559.0                13.0   \n",
      "88               1542.0          21793.0                15.0   \n",
      "90               1786.0          25182.0                15.0   \n",
      "116               514.0           7464.0                19.0   \n",
      "\n",
      "                        image_path   onset  ...  subject_index  is_duplicate  \\\n",
      "14           crayon/crayon_15s.jpg   23.70  ...              0         False   \n",
      "84   typewriter/typewriter_13s.jpg  129.85  ...              0         False   \n",
      "88       starfish/starfish_15n.jpg  135.80  ...              0         False   \n",
      "90               wasp/wasp_15n.jpg  138.85  ...              0         False   \n",
      "116            dough/dough_19s.jpg  177.45  ...              0         False   \n",
      "\n",
      "     trial_type_y  session  run  subject_id  trial_id  \\\n",
      "14           test        1    2           1        98   \n",
      "84           test        1    7           1       505   \n",
      "88           test        1    5           1       378   \n",
      "90           test        1    2           1       115   \n",
      "116          test        1   10           1       776   \n",
      "\n",
      "                          stimulus     concept  \\\n",
      "14           crayon/crayon_15s.jpg      crayon   \n",
      "84   typewriter/typewriter_13s.jpg  typewriter   \n",
      "88       starfish/starfish_15n.jpg    starfish   \n",
      "90               wasp/wasp_15n.jpg        wasp   \n",
      "116            dough/dough_19s.jpg       dough   \n",
      "\n",
      "                                                   svd  \n",
      "14   [2.1053042433131592, 4.340530565659662, 0.6523...  \n",
      "84   [2.873967263910083, 6.069218972120035, -2.9831...  \n",
      "88   [-4.7914706601465, 1.4800827569001156, -0.6594...  \n",
      "90   [2.4368416216978193, 1.998792086775452, -3.898...  \n",
      "116  [-9.32772809092621, 5.924464477538022, -0.1210...  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "valid_epochs_test_small_list = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    valid_epochs = valid_epochs_all_test_small_fmri_subset.copy()\n",
    "    merge_into_epochs(valid_epochs, df)\n",
    "    valid_epochs_test_small_list.append(valid_epochs)\n",
    "\n",
    "valid_epochs_all_test_small_fmri_subset = mne.concatenate_epochs(valid_epochs_test_small_list)\n",
    "assert valid_epochs_all_test_small_fmri_subset.metadata['stimulus'].isna().sum() == 0\n",
    "print(len(valid_epochs_all_test_small_fmri_subset))\n",
    "print(valid_epochs_all_test_small_fmri_subset.metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_epochs_all_train_meg_fmri_combined.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_epochs_all_train_fmri_subset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_epochs_all_test_meg_fmri_combined.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_epochs_all_test_fmri_subset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_epochs_all_test_small_meg_fmri_combined.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_epochs_all_test_small_fmri_subset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
